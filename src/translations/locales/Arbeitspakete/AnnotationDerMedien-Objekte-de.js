    export default {
    
    (29786113,'<h1>Mitwirkende</h1><h2>Verantwortliche</h2><p><ac:link><ri:user ri:userkey=\"036a0e4f4d328b24014d328d41710002\" /><ac:plain-text-link-body><![CDATA[Daniel Röwenstrunk]]></ac:plain-text-link-body></ac:link>, <ac:link><ri:user ri:userkey=\"036a0e4f4e25dcd9014e4a3be5500006\" /></ac:link>, <ac:link><ri:user ri:userkey=\"036a0e4f4e25dcd9014e499e96a50003\" /></ac:link>, <ac:link><ri:user ri:userkey=\"036a0e4f4e25dcd9014f8523503c0009\" /></ac:link></p><h2>Bearbeiter</h2><p><ac:link><ri:user ri:userkey=\"036a0e4f4d6bb32d014daed146920005\" /></ac:link>, <ac:link><ri:user ri:userkey=\"036a0e4f4d6bb32d014e0145769a000a\" /></ac:link>, <ac:link><ri:user ri:userkey=\"036a0e4f4d33bc30014d43d6ab930002\" /></ac:link>, <ac:link><ri:user ri:userkey=\"036a0e4f4d6bb32d014db975f2d20007\" /></ac:link></p><h1>Zeitraum</h1><p><time datetime=\"2016-03-01\" /> bis&nbsp;<time datetime=\"2017-02-28\" />&nbsp;</p><h1>Abh&auml;ngigkeiten</h1><p>Ergebnisse kommen von&nbsp;<ac:link><ri:page ri:content-title=\"AP 1.3.2 Annotationsmodelle speziell f&uuml;r nicht-textuelle Objekte\" /><ac:plain-text-link-body><![CDATA[AP 1.3 Annotationsmodelle speziell für nicht-textuelle Objekte]]></ac:plain-text-link-body></ac:link></p><p>Ergebnisse kommen von&nbsp;<ac:link><ri:page ri:content-title=\"AP 2.1.3 Sequenz-Editor und Player f&uuml;r synchronisierte Medienwiedergabe\" /><ac:plain-text-link-body><![CDATA[AP 2.1 Sequenz-Editor und Player für synchronisierte Medienwiedergabe]]></ac:plain-text-link-body></ac:link></p><h1>Inhalt</h1><p>Ebenso wird für die Annotation der Medien-Objekte eine umfassende Unterstützung entwickelt. Neben einfachen textbasierten Annotationen sollen auch strukturierte Annotationen (wie z.B. die Definition von Geo-Informationen) für die spezielle Funktionalität ermöglicht werden. Eine entscheidende Annotationsform ist dabei die Verknüpfung verschiedener Medientypen, beispielsweise Notentext&ndash;Audio, Notencodierung&ndash;Scan eines Autographs, usw. Hierfür sollen Werkzeuge zur Verknüpfung verschiedener nicht-textueller Objekte entwickelt werden; dabei gilt es, sowohl für die Darstellung als auch für die Annotation und die Verknüpfung verschiedener Medien ein modulares Architekturkonzept (aubauend auf den Codierungskonzepten in AP 1.3) zu entwickeln, das die Aufnahme von neu hinzukommenden Typen nicht-textueller Objekte erleichtert.</p><h2>ZemFI</h2><ul><li>Verkn&uuml;pfung verschiedener MEdientypen (audio / Video)</li><li>syncPlayer aus FreiDi weiterentwickeln (<ac:link><ri:user ri:userkey=\"036a0e4f4d6bb32d014db975f2d20007\" /></ac:link>)<br /><ul><li>Kooperation &quot;International Audiolabs, Erlangen&quot; bzgl. Tools zur Erstellung von Syncdaten</li></ul></li><li>Sequenz-Editor und -Player f&uuml;r synchronisierte Medienwiedergabe (<ac:link><ri:user ri:userkey=\"036a0e4f4d33bc30014d43d6ab930002\" /></ac:link>)</li></ul><h1>Ergebnis</h1><p>&nbsp;</p><h1>Offene Punkte</h1>',29753345,2),

    
    }